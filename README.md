# Nvidia End-to-End Self-Driving Cars

This is an implementation of [Nvidia End-to-End Self-Driving Cars](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf) using Tensorflow. 


## Introduction

This end-to-end system is an implementation of predicting *steering* angle for self-driving cars using behavior cloning method. 

Its network architecture is

    RGB Image captured by Frontal Camera -> Convolution Layers x 5 -> Fully-Connected Layers x 5 -> Prediction Result

with size of each output (channel @ height x width)

    3@22x600 -> 24@31x98 -> 36@14x47 -> 48@5x22 -> 64@3x20 -> 64@1x18 -> 1164 -> 100 -> 50 -> 10 -> 1

The first three convolution layers have a 5x5 kernel with 2x2 stride. The last two convolution layers have a 3x3 kernel with 1x1 stride. No padding is used.

Human driving data and Mean Squared Error (MSE) loss are used for training.

### Data Augmentation

It is very time consuming and annoying to collect data for almost all behavior cloning tasks.

The original paper augments data by adding artificial shift and rotations.

We implement data augmentation by rotations and using images captured by left, right cameras installed on the car.  

### Modification

There are some modifications we made beyond the original paper.
+ [BatchNorm](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm) is attached to each convolution layers.
+ [ELU](https://www.tensorflow.org/api_docs/python/tf/nn/elu) is used as activation following each BatchNorm layers.
+ 1x1 Convolution Layers are used to replace fully-connected layers
+ [Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) is used at the position between the convolution layer and the fully-connected layer.

See `model.py` or run `tensorboard --logdir=./pre-trained/log` to see more details.


## Usage

Running Environment: Python 3

Python Package Dependencies:
+ opencv-python
+ tensorflow

Configuration File: `config.py`

### Train

1. Fill in your own training dataset path in `config.py`
    
    `TRAINING_DATA_DIR`: the directory where the data are

    `TRAINING_DATA_FILE`: the data list file

    The data list file should be in the format same to that generated by Udacity's Self-Driving Car Simulator. It is a CSV file, in which the header (1st) line is 

    center, left, right, steering, throttle, brake, speed

    The first 3rd fields are the image file pathes, related to `TRAINING_DATA_DIR`, which are captured by the center, left and right cameras. The `steering` field is the steering angle collected from human. The last three fields are not used by this program.

    A dataset collected (not by me) from Track 1 of Udacity's Self-Driving Car Simulator is provided in `data` folder.


2. Change `ANGLE_DELTA_CORRECTION_LEFT`, `ANGLE_DELTA_CORRECTION_RIGHT` and `INPUT_IMAGE_CROP` in `config.py`.

    0.2 and -0.2 for data collected from Udacity's Self-Driving Car Simulator.

3. Run `python train.py`.


### Simulation

Simulation can be conducted in [Udacity's Self-Driving Car Simulator](https://github.com/udacity/self-driving-car-sim).

1. Download the simulator depending on your OS from [Udacity's Self-Driving Car Simulator](https://github.com/udacity/self-driving-car-sim).
2. Change the model checkpoint folder `SAVE_FOLDER` and log folder `LOG_FOLDER` in `config.py`. 
2. Running the model by `python sim.py`.
3. Running the simulator; Choose `AUTONOMOUS MODE`.

A pre-trained model is provided in `pre-trained` folder.

The communication between the simulator and the model script depends on the following Python package:

+ eventlet
+ Flask
+ socketio

See [Issue 1](https://github.com/xupei0610/nvidia-end-to-end-self-driving-cars/issues/1) if a similar problem is encountered after installing `scoketio` by `pip`.
